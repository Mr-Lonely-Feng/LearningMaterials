
代码：
    sum(col(column_name).isNull().cast('integer')).alias(column_name)
    - 判断DataFrame中某一列是否为null
        col(column_name).isNull()
        col(column_name)表示的是将字符串转换为列Column对象
    - 将布尔类型值转换为转型
        .cast('integer')
        说明：
            - 布尔值为true：1
            - 布尔值为false：0
    - 给聚合后的值，起一个别名
        列的名称


针对于大数据领域数据分析来说
    - SQL
    - JAVA
    - SCALA - SPARK、KAFAK
    - Python 
        - Spark框架
        - HBase 
HBase
    基于HADOOP(HDFS)之上的数据库，NoSQL数据库，分布式、可扩展、高可用
    表中的数据量：非常非常大，查询速度很快
    - Java API
        对数据库表的数据进行读写
    - 集成其他框架
        Hive、Phonix（凤凰，建议在HBase之上）
    - 其他语言
        Python语言最多
        尤其在游戏公司和互联数据分析公司

Python 如何访问HBase表的数据
    - 启动HBase Thrift服务
        $ bin/hbase-daemon.sh start thrift
        默认情况下，启动9090端口，用于Client访问。
    - 开发调用
- 第一步、生成HBase对应的python模块文件
    自己生成，Thrift文件在
    ${HBASE_HOME}/hbase-thrift/src/main/resources/org/apache/hadoop/hbase
    执行命令：
        thrift --gen py Hbase.thrift
    此时：要在Linux环境安装Thrift框架。
        - 下载：
            http://archive.apache.org/dist/thrift/0.9.3/
        - 编译安装：
            参考文档
            http://thrift.apache.org/docs/install/centos
- 第二步、在Python下安装thrift模块
    - 在Windos下开发，使用Anaconda2,直接使用命令
        pip install thrift 
    - 在Linux下环境下
        安装模块
        thrift-0.9.3\lib\py执行命令
            sudo python setup.py install 
