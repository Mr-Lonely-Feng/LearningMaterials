shuffle操作是spark中唯一最最消耗性能的地方
因此也就成了最需要进行性能调优的地方，最需要解决线上报错的地方，也是唯一可能出现数据倾斜的地方
因为shuffle过程中，会产生大量的磁盘IO、数据序列化和反序列化、网络IO

为了实施shuffle操作
spark中才有了stage的概念，在发生shuffle操作的算子中，进行stage的拆分
shuffle操作的前半部分，是上一个stage来进行，也称之为map task，shuffle操作的后半部分，是下一个stage来进行，也称之为reduce task
其中map task负责数据的组织，也就是将同一个key对应的value都写入同一个下游task对应的分区文件中
其中reduce task负责数据的聚合，也就是将上一个stage的task所在节点上，将属于自己的各个分区文件，都拉取过来聚合
这种模型，是参考和模拟了MapReduce的shuffle过程来的

map task会将数据先保存在内存中，如果内存不够时，就溢写到磁盘文件中去
reduce task会读取各个节点上属于自己的分区磁盘文件，到自己节点的内存中，并进行聚合

shuffle操作会消耗大量的内存，因为无论是网络传输数据之前，还是之后，都会使用大量的内存中数据结构来实施聚合操作
比如reduceByKey和aggregateByKey操作，会在map side使用内存中的数据结构进行预先聚合
其他的byKey类的操作，都是在reduce side，使用内存数据结构进行聚合
在聚合过程中，如果内存不够，只能溢写到磁盘文件中去，此时就会发生大量的磁盘IO，降低性能

此外，shuffle过程中，还会产生大量的中间文件，也就是map side写入的大量分区文件
比如Spark 1.3版本，这些中间文件会一致保留着，直到RDD不再被使用，而且被垃圾回收掉了，才会去清理中间文件
这主要是为了，如果要重新计算shuffle后的RDD，那么map side不需要重新做一次磁盘写操作
但是这种情况下，如果我们的应用程序中，一直保持着对RDD的引用，导致很长时间以后才会进行RDD垃圾回收操作
保存中间文件的目录，由spark.local.dir属性指定

内存的消耗、磁盘IO、网络数据传输（IO）
