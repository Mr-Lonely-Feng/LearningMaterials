yarn模式下调试运行中的spark作业

在yarn模式下，spark作业运行相关的executor和ApplicationMaster都是运行在yarn的container中的
一个作业运行完了以后，yarn有两种方式来处理spark作业打印出的日志

第一种是聚合日志方式（推荐，比较常用）

这种方式的话，顾名思义，就是说，将散落在集群中各个机器上的日志，最后都给聚合起来，让我们可以统一查看
如果打开了日志聚合的选项，即yarn.log-aggregation-enable，container的日志会拷贝到hdfs上去，并从机器中删除

对于这种情况，可以使用yarn logs -applicationId <app ID>命令，来查看日志
yarn logs命令，会打印出application对应的所有container的日志出来，当然，因为日志是在hdfs上的，我们自然也可以通过hdfs的命令行来直接从hdfs中查看日志
日志在hdfs中的目录，可以通过查看yarn.nodemanager.remote-app-log-dir和yarn.nodemanager.remote-app-log-dir-suffix属性来获知

第二种 web ui（如果你有精力的话，可以去配一下）

日志也可以通过spark web ui来查看executor的输出日志
但是此时需要启动History Server，需要让spark history server和mapreduce history server运行着
并且在yarn-site.xml文件中，配置yarn.log.server.url属性
spark history server web ui中的log url，会将你重定向到mapreduce history server上，去查看日志

第三种 分散查看（通常不推荐）

如果没有打开聚合日志选项，那么日志默认就是散落在各个机器上的本次磁盘目录中的，在YARN_APP_LOGS_DIR目录下
根据hadoop版本的不同，通常在/tmp/logs目录下，或者$HADOOP_HOME/logs/userlogs目录下
如果你要查看某个container的日志，那么就得登录到那台机器上去，然后到指定的目录下去，找到那个日志文件，然后才能查看
